# This is where Meta Lingua will store anything related to the experiment.
dump_dir: /workspace/AI-Uncomplicated/
name: "debug"
steps: 1000

seed: 12

optim:
    lr: 3e-4
    warmup: 2000
    lr_min_ratio: 0.000001
    clip: 10.0

distributed:
    fsdp_type: full_shard
    compile: true
    selective_activation_checkpointing: false

model:
    dim: 1024
    n_layers: 8
    n_heads: 8

data:
    root_dir: /workspace/artifact/pretraining_data/
    sources:
      TigerResearch: 100.0
    batch_size: 32
    seq_len: 1024
    load_async: true
    tokenizer:
        name: sp
        path: /workspace/artifact/tokenizer/GI01-tokenizer-v0.1-en/spm_buffer.model